{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krish6115/MLLab/blob/main/Lab3/Lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzR384P_GR2Q",
        "outputId": "a99aae4d-80f5-4041-ea74-23e114cf589b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A1 — Class centroids/spreads and interclass distance\n",
            "Classes: rice vs maize\n",
            "Centroid distance: 153.7258\n",
            "  rice centroid (first 4 dims): [79.89   47.58   39.87   23.6893]\n",
            "  rice spread   (first 4 dims): [11.8582  7.8653  2.9314  2.0211]\n",
            "  maize centroid (first 4 dims): [77.76   48.44   19.79   22.3892]\n",
            "  maize spread   (first 4 dims): [11.8896  7.9703  2.9268  2.6659]\n",
            "\n",
            "A2 — Histogram, mean, variance for feature: temperature\n",
            "{\n",
            "  \"feature\": \"temperature\",\n",
            "  \"bins\": 12,\n",
            "  \"counts\": [\n",
            "    14,\n",
            "    10,\n",
            "    7,\n",
            "    15,\n",
            "    16,\n",
            "    15,\n",
            "    17,\n",
            "    26,\n",
            "    14,\n",
            "    27,\n",
            "    22,\n",
            "    17\n",
            "  ],\n",
            "  \"bin_edges\": [\n",
            "    18.04185513,\n",
            "    18.782529766666666,\n",
            "    19.52320440333333,\n",
            "    20.26387904,\n",
            "    21.004553676666667,\n",
            "    21.74522831333333,\n",
            "    22.48590295,\n",
            "    23.226577586666664,\n",
            "    23.967252223333332,\n",
            "    24.70792686,\n",
            "    25.44860149666667,\n",
            "    26.189276133333333,\n",
            "    26.92995077\n",
            "  ],\n",
            "  \"mean\": 23.039268060350004,\n",
            "  \"variance\": 6.018575201679887\n",
            "}\n",
            "\n",
            "A3 — Minkowski distance r=1..10 between first two samples\n",
            "{\n",
            "  \"r\": [\n",
            "    1,\n",
            "    2,\n",
            "    3,\n",
            "    4,\n",
            "    5,\n",
            "    6,\n",
            "    7,\n",
            "    8,\n",
            "    9,\n",
            "    10\n",
            "  ],\n",
            "  \"distance\": [\n",
            "    49.82893039899999,\n",
            "    29.181346874655944,\n",
            "    26.00217570838137,\n",
            "    24.872999843849197,\n",
            "    24.350104535733717,\n",
            "    24.078885652178812,\n",
            "    23.929723222342414,\n",
            "    23.844768469246727,\n",
            "    23.79523557248022,\n",
            "    23.7658565696987\n",
            "  ]\n",
            "}\n",
            "\n",
            "A6 — Test accuracy (k=3): 1.0\n",
            "\n",
            "A7 — First 10 predictions (original labels): ['rice', 'maize', 'rice', 'rice', 'rice', 'rice', 'maize', 'rice', 'maize', 'rice']\n",
            "\n",
            "A8 — Accuracy vs k (1..11):\n",
            "{\n",
            "  \"k\": [\n",
            "    1,\n",
            "    2,\n",
            "    3,\n",
            "    4,\n",
            "    5,\n",
            "    6,\n",
            "    7,\n",
            "    8,\n",
            "    9,\n",
            "    10,\n",
            "    11\n",
            "  ],\n",
            "  \"accuracy\": [\n",
            "    1.0,\n",
            "    1.0,\n",
            "    1.0,\n",
            "    1.0,\n",
            "    1.0,\n",
            "    1.0,\n",
            "    1.0,\n",
            "    1.0,\n",
            "    1.0,\n",
            "    1.0,\n",
            "    1.0\n",
            "  ]\n",
            "}\n",
            "\n",
            "A9 — Confusion matrices and metrics (k=3):\n",
            "{\n",
            "  \"train\": {\n",
            "    \"confusion_matrix\": [\n",
            "      [\n",
            "        70,\n",
            "        0\n",
            "      ],\n",
            "      [\n",
            "        0,\n",
            "        70\n",
            "      ]\n",
            "    ],\n",
            "    \"precision\": 1.0,\n",
            "    \"recall\": 1.0,\n",
            "    \"f1_score\": 1.0,\n",
            "    \"accuracy\": 1.0\n",
            "  },\n",
            "  \"test\": {\n",
            "    \"confusion_matrix\": [\n",
            "      [\n",
            "        30,\n",
            "        0\n",
            "      ],\n",
            "      [\n",
            "        0,\n",
            "        30\n",
            "      ]\n",
            "    ],\n",
            "    \"precision\": 1.0,\n",
            "    \"recall\": 1.0,\n",
            "    \"f1_score\": 1.0,\n",
            "    \"accuracy\": 1.0\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Lab03 – k-NN on Crop_recommendation.csv (Two-class subset)\n",
        "# Dataset columns: N,P,K,temperature,humidity,ph,rainfall,label\n",
        "# All functions are defined here (single code block) per rules.\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Tuple, Dict, List\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    accuracy_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve\n",
        ")\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Utility: Data loading/select\n",
        "def load_dataset(csv_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    A0. Utility\n",
        "    Load the Crop Recommendation dataset from a CSV path.\n",
        "    Returns a pandas DataFrame.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "    return df\n",
        "\n",
        "\n",
        "def select_two_classes(df: pd.DataFrame, class_a: str, class_b: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    A0. Utility\n",
        "    Filter the dataset to keep only two classes (binary problem), as required by Lab03.\n",
        "    Returns a DataFrame containing only rows whose 'label' ∈ {class_a, class_b}.\n",
        "    \"\"\"\n",
        "    subset = df[df['label'].isin([class_a, class_b])].copy()\n",
        "    subset.reset_index(drop=True, inplace=True)\n",
        "    return subset\n",
        "\n",
        "\n",
        "def split_features_labels(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:\n",
        "    \"\"\"\n",
        "    A0. Utility\n",
        "    Split the two-class DataFrame into X (features) and y (labels).\n",
        "    \"\"\"\n",
        "    X = df.drop(columns=['label'])\n",
        "    y = df['label'].copy()\n",
        "    return X, y\n",
        "\n",
        "# A1. Intraclass spread and interclass centroid dist\n",
        "def compute_class_stats(X: pd.DataFrame, y: pd.Series) -> Dict[str, Dict[str, np.ndarray]]:\n",
        "    \"\"\"\n",
        "    A1.\n",
        "    Compute class centroids (mean vectors) and spreads (std vectors) for each class.\n",
        "    Returns a dict: {class_label: {'centroid': np.ndarray, 'spread': np.ndarray}}\n",
        "    \"\"\"\n",
        "    stats = {}\n",
        "    for cls in y.unique():\n",
        "        Xc = X[y == cls]\n",
        "        centroid = Xc.mean(axis=0).to_numpy()\n",
        "        spread = Xc.std(axis=0, ddof=0).to_numpy()\n",
        "        stats[cls] = {'centroid': centroid, 'spread': spread}\n",
        "    return stats\n",
        "\n",
        "\n",
        "def compute_centroid_distance(stats: Dict[str, Dict[str, np.ndarray]], class_a: str, class_b: str) -> float:\n",
        "    \"\"\"\n",
        "    A1.\n",
        "    Compute Euclidean distance between two class centroids.\n",
        "    \"\"\"\n",
        "    c1 = stats[class_a]['centroid']\n",
        "    c2 = stats[class_b]['centroid']\n",
        "    return float(np.linalg.norm(c1 - c2))\n",
        "\n",
        "# A2. Histogram, mean and variance for a chosen feature\n",
        "def feature_histogram_stats(\n",
        "    X: pd.DataFrame,\n",
        "    feature_name: str,\n",
        "    bins: int = 10\n",
        ") -> Dict[str, object]:\n",
        "    \"\"\"\n",
        "    A2.\n",
        "    Compute histogram for a single feature using numpy.histogram.\n",
        "    Also compute mean and variance of that feature.\n",
        "    Returns a dict containing counts, bin_edges, mean, variance.\n",
        "    \"\"\"\n",
        "    values = X[feature_name].to_numpy()\n",
        "    counts, bin_edges = np.histogram(values, bins=bins)\n",
        "    return {\n",
        "        'feature': feature_name,\n",
        "        'bins': int(bins),\n",
        "        'counts': counts.tolist(),\n",
        "        'bin_edges': bin_edges.tolist(),\n",
        "        'mean': float(np.mean(values)),\n",
        "        'variance': float(np.var(values))\n",
        "    }\n",
        "\n",
        "# A3. Minkowski distance between two feature vectors for r=1..10\n",
        "def minkowski_curve(\n",
        "    vec1: np.ndarray,\n",
        "    vec2: np.ndarray,\n",
        "    r_min: int = 1,\n",
        "    r_max: int = 10\n",
        ") -> Dict[str, List[float]]:\n",
        "    \"\"\"\n",
        "    A3.\n",
        "    Compute Minkowski distances between two vectors for orders r = r_min..r_max.\n",
        "    Returns a dict with the r values and the corresponding distances.\n",
        "    \"\"\"\n",
        "    rs = list(range(r_min, r_max + 1))\n",
        "    dists = []\n",
        "    for r in rs:\n",
        "        d = np.power(np.sum(np.abs(vec1 - vec2) ** r), 1.0 / r)\n",
        "        dists.append(float(d))\n",
        "    return {'r': rs, 'distance': dists}\n",
        "\n",
        "# A4. Train-test split (with scaling kept optional and outside)\n",
        "def train_test_split_binary(\n",
        "    X: pd.DataFrame,\n",
        "    y: pd.Series,\n",
        "    test_size: float = 0.3,\n",
        "    random_state: int = 42,\n",
        "    scale: bool = True\n",
        ") -> Dict[str, object]:\n",
        "    \"\"\"\n",
        "    A4.\n",
        "    Perform a train-test split. Optionally standardize features using StandardScaler.\n",
        "    Returns a dict with X_train, X_test, y_train, y_test, and scaler (if used).\n",
        "    Note: labels are encoded to integers (0/1) to support ROC if needed.\n",
        "    \"\"\"\n",
        "    le = LabelEncoder()\n",
        "    y_enc = le.fit_transform(y)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X.values, y_enc, test_size=test_size, random_state=random_state, stratify=y_enc\n",
        "    )\n",
        "    scaler = None\n",
        "    if scale:\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "    return {\n",
        "        'X_train': X_train, 'X_test': X_test,\n",
        "        'y_train': y_train, 'y_test': y_test,\n",
        "        'label_encoder': le, 'scaler': scaler\n",
        "    }\n",
        "\n",
        "# A5–A7. Train kNN, score, and predictions\n",
        "def train_knn_classifier(\n",
        "    X_train: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    k_neighbors: int = 3,\n",
        "    metric: str = 'minkowski',\n",
        "    p: int = 2\n",
        ") -> KNeighborsClassifier:\n",
        "    \"\"\"\n",
        "    A5.\n",
        "    Train a k-NN classifier with given hyperparameters.\n",
        "    \"\"\"\n",
        "    clf = KNeighborsClassifier(n_neighbors=k_neighbors, metric=metric, p=p)\n",
        "    clf.fit(X_train, y_train)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def evaluate_accuracy(\n",
        "    clf: KNeighborsClassifier,\n",
        "    X_test: np.ndarray,\n",
        "    y_test: np.ndarray\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    A6.\n",
        "    Compute accuracy on the test set.\n",
        "    \"\"\"\n",
        "    return float(clf.score(X_test, y_test))\n",
        "\n",
        "\n",
        "def predict_labels(\n",
        "    clf: KNeighborsClassifier,\n",
        "    X_test: np.ndarray\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    A7.\n",
        "    Predict labels for test vectors.\n",
        "    \"\"\"\n",
        "    return clf.predict(X_test)\n",
        "\n",
        "# A8. Vary k from 1 to 11 and collect accuracy vs k (curve)\n",
        "def k_sweep_accuracy(\n",
        "    X_train: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    X_test: np.ndarray,\n",
        "    y_test: np.ndarray,\n",
        "    k_min: int = 1,\n",
        "    k_max: int = 11,\n",
        "    metric: str = 'minkowski',\n",
        "    p: int = 2\n",
        ") -> Dict[str, List[float]]:\n",
        "    \"\"\"\n",
        "    A8.\n",
        "    Sweep k from k_min to k_max and return accuracies for each k.\n",
        "    \"\"\"\n",
        "    ks = list(range(k_min, k_max + 1))\n",
        "    accs = []\n",
        "    for k in ks:\n",
        "        clf = KNeighborsClassifier(n_neighbors=k, metric=metric, p=p)\n",
        "        clf.fit(X_train, y_train)\n",
        "        acc = accuracy_score(y_test, clf.predict(X_test))\n",
        "        accs.append(float(acc))\n",
        "    return {'k': ks, 'accuracy': accs}\n",
        "\n",
        "# A9. Confusion matrix and metrics (precision/recall/F1)\n",
        "def compute_confusion_and_metrics(\n",
        "    clf: KNeighborsClassifier,\n",
        "    X_train: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    X_test: np.ndarray,\n",
        "    y_test: np.ndarray\n",
        ") -> Dict[str, Dict[str, float]]:\n",
        "    \"\"\"\n",
        "    A9.\n",
        "    Compute confusion matrices and precision/recall/F1 for train and test sets.\n",
        "    Also returns accuracies for both splits.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    for split_name, Xs, ys in [('train', X_train, y_train), ('test', X_test, y_test)]:\n",
        "        y_pred = clf.predict(Xs)\n",
        "        cm = confusion_matrix(ys, y_pred)\n",
        "        prec = precision_score(ys, y_pred, zero_division=0)\n",
        "        rec = recall_score(ys, y_pred, zero_division=0)\n",
        "        f1 = f1_score(ys, y_pred, zero_division=0)\n",
        "        acc = accuracy_score(ys, y_pred)\n",
        "        results[split_name] = {\n",
        "            'confusion_matrix': cm.tolist(),\n",
        "            'precision': float(prec),\n",
        "            'recall': float(rec),\n",
        "            'f1_score': float(f1),\n",
        "            'accuracy': float(acc)\n",
        "        }\n",
        "    return results\n",
        "\n",
        "# Main Program\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Load and choose two classes for binary classification\n",
        "    df_full = load_dataset(\"Crop_recommendation.csv\")\n",
        "    class_a = \"rice\"       # choose any class present in the CSV\n",
        "    class_b = \"maize\"      # choose another class\n",
        "    df_bin = select_two_classes(df_full, class_a, class_b)\n",
        "    X, y = split_features_labels(df_bin)\n",
        "\n",
        "    # 2) A1: Intraclass stats and interclass centroid distance\n",
        "    stats = compute_class_stats(X, y)\n",
        "    centroid_distance = compute_centroid_distance(stats, class_a, class_b)\n",
        "\n",
        "    print(\"A1 — Class centroids/spreads and interclass distance\")\n",
        "    print(f\"Classes: {class_a} vs {class_b}\")\n",
        "    print(f\"Centroid distance: {centroid_distance:.4f}\")\n",
        "    for cls in [class_a, class_b]:\n",
        "        print(f\"  {cls} centroid (first 4 dims): {np.round(stats[cls]['centroid'][:4], 4)}\")\n",
        "        print(f\"  {cls} spread   (first 4 dims): {np.round(stats[cls]['spread'][:4], 4)}\")\n",
        "\n",
        "    # 3) A2: Histogram stats for a chosen feature\n",
        "    feature_name = \"temperature\"  # choose any single feature\n",
        "    hist_info = feature_histogram_stats(X, feature_name, bins=12)\n",
        "    print(\"\\nA2 — Histogram, mean, variance for feature:\", feature_name)\n",
        "    print(json.dumps(hist_info, indent=2))\n",
        "\n",
        "    # 4) A3: Minkowski distance between two arbitrary vectors (first two rows)\n",
        "    v1 = X.iloc[0].to_numpy(dtype=float)\n",
        "    v2 = X.iloc[1].to_numpy(dtype=float)\n",
        "    mink_curve = minkowski_curve(v1, v2, r_min=1, r_max=10)\n",
        "    print(\"\\nA3 — Minkowski distance r=1..10 between first two samples\")\n",
        "    print(json.dumps(mink_curve, indent=2))\n",
        "\n",
        "    # 5) A4: Train-test split (with scaling)\n",
        "    split = train_test_split_binary(X, y, test_size=0.3, random_state=42, scale=True)\n",
        "    X_train, X_test = split['X_train'], split['X_test']\n",
        "    y_train, y_test = split['y_train'], split['y_test']\n",
        "    label_encoder = split['label_encoder']\n",
        "\n",
        "    # 6) A5: Train kNN (k=3)\n",
        "    knn_k3 = train_knn_classifier(X_train, y_train, k_neighbors=3, metric='minkowski', p=2)\n",
        "\n",
        "    # 7) A6: Test accuracy\n",
        "    test_acc_k3 = evaluate_accuracy(knn_k3, X_test, y_test)\n",
        "    print(\"\\nA6 — Test accuracy (k=3):\", round(test_acc_k3, 4))\n",
        "\n",
        "    # 8) A7: Predictions for test set\n",
        "    y_pred_test = predict_labels(knn_k3, X_test)\n",
        "    y_pred_labels = label_encoder.inverse_transform(y_pred_test)\n",
        "    print(\"\\nA7 — First 10 predictions (original labels):\", y_pred_labels[:10].tolist())\n",
        "\n",
        "    # 9) A8: Accuracy vs k (1..11)\n",
        "    sweep = k_sweep_accuracy(X_train, y_train, X_test, y_test, k_min=1, k_max=11, metric='minkowski', p=2)\n",
        "    print(\"\\nA8 — Accuracy vs k (1..11):\")\n",
        "    print(json.dumps(sweep, indent=2))\n",
        "\n",
        "    # 10) A9: Confusion matrices and metrics (train/test)\n",
        "    perf = compute_confusion_and_metrics(knn_k3, X_train, y_train, X_test, y_test)\n",
        "    print(\"\\nA9 — Confusion matrices and metrics (k=3):\")\n",
        "    print(json.dumps(perf, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "2db33ff6",
        "outputId": "d8eaef7c-0240-4b50-cff3-d17d81b2044b"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-60f527eb-717e-4f5c-ad37-b80d68b6673f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-60f527eb-717e-4f5c-ad37-b80d68b6673f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Crop_recommendation.csv to Crop_recommendation.csv\n"
          ]
        }
      ]
    }
  ]
}